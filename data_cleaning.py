# -*- coding: utf-8 -*-
"""Data_cleaning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1E_AXLi4xrwqolVuGkv7sHHcxdyckiL05
"""

import pandas as pd
import numpy as np

data = pd.read_csv('/content/drive/MyDrive/ Dataset/laptopData.csv')
data

data.drop('Unnamed: 0',axis=1,inplace=True)
data

#to get first five rows of the data
data.head(5)

data.sample(4)#sample gives any 4 rows of the table

data.info()

data.describe()

#to find the duplicated rows in the table
data.duplicated().sum()# gives the total count of the duplicated values in the dataset

data.select_dtypes('object').describe() # selecting columns based on datatypes. object datatype gives the

# explore with Company column
data['Company'].value_counts(dropna=False) #counts howmany times unique value is updated

data[data['Company']=='vero']

# unique values and see any speces have with this value
data['Company'].unique()

data['Company'].isna().sum()

data['TypeName'].unique()

data['TypeName'].dtype

data['Inches'].value_counts(dropna=False) # shows the inconsistencies

# that values is cm not inches so need to convert into inches
data[data['Inches'] == '25.6']

data['Inches'].unique()

data['ScreenResolution'].str.split('HD').str.get(0).str.split('Display').str.get(0).value_counts()

data['ScreenResolution'].str.extract(r'([A-Za-z\s]+) Panel').value_counts(dropna=False)

# Regular expression pattern to find resolutions
pattern = r'\b\d{3,4}x\d{3,4}\b'

# Find resolutions for each value in the Series
data['ScreenResolution'].str.findall(pattern).str.get(0).value_counts().index

data[data['ScreenResolution'].fillna('').str.contains('Full HD', case=False)]

data['Cpu'].unique()

## in first two rows that ram size should be 8gb according to google
data[data['Ram'] == '64GB']

data['Memory'].value_counts().index

data['Memory'].value_counts()

data['Gpu'].str.split(' ').str.get(0).value_counts()

data['Gpu'].unique()

data['OpSys'].value_counts()

data[data['OpSys'] == 'Android']

data['OpSys'].unique()

k = data['Weight'].str.split('kg').str.get(0).dropna().str.replace('?','1.1111').unique()
print(k)

#no of missing values
data.isna().sum()

# number of duplicated rows
data.duplicated().sum()

"""Data Cleaning Order
Quality -> Completeness
Structural -> Messy
Quality -> Validity
Quality -> Accuracy
Quality -> Consistency

solve completeness issue

Solve structural issue solve screen resolution structural problem
Solve CPU structural problem

"""

#solve completeness issue
# shape of dataframe before drop nan rows
data.shape

# 30 rows out of 1303 are totally missing along with their 11 columns
# that's why i drop all missing values
data= data.dropna().reset_index(drop=True)

# shape of dataframe after drop nan row
data.shape

data.drop_duplicates(inplace=True)

data.shape

data.loc[data['Memory']=='?','Memory']='1TB HDD'

#solve structural issues
pattern =